{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "TL_VGG16_Stem In Bangla.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXNwWa30IVjS"
      },
      "source": [
        "**IMAGE CLASSIFICATION (CATS VS DOGS) WITH TRANSFER LEARNING (VGG16 ALGORITHM)**\n"
      ],
      "id": "yXNwWa30IVjS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ca12a822"
      },
      "source": [
        "from google.colab import drive"
      ],
      "id": "ca12a822",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lc0d1M6DTxA",
        "outputId": "15f3c7ec-dfcc-4217-bcb7-8d09ce019608"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "id": "3lc0d1M6DTxA",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m96QN9bxFCwU"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "id": "m96QN9bxFCwU",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psYFk2K6ErGT"
      },
      "source": [
        "base_dir= r\"/content/drive/MyDrive/Dataset/dog_vs_cat/dataset\""
      ],
      "id": "psYFk2K6ErGT",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8a00d50"
      },
      "source": [
        "#preprocessing\n",
        "image_sz=224\n",
        "batch_sz=16\n",
        "\n",
        "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "\n",
        "    \n",
        "    rescale=1./255,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1)\n",
        "\n",
        "validation_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    \n",
        "    validation_split=0.1\n",
        ")"
      ],
      "id": "f8a00d50",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e377ab96",
        "outputId": "a1f11dc1-b6ab-4fca-cdf1-4d4a44cbb6eb"
      },
      "source": [
        "#train_Data_Portion\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(image_sz,image_sz),\n",
        "    batch_size=batch_sz,\n",
        "    subset='training'\n",
        "\n",
        ")\n",
        "\n",
        "validation_generator=validation_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(image_sz,image_sz),\n",
        "    batch_size=batch_sz,\n",
        "    subset='validation'\n",
        "\n",
        ")"
      ],
      "id": "e377ab96",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd5aeee2"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from glob import glob"
      ],
      "id": "fd5aeee2",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e78347e0",
        "outputId": "56d63201-5c96-413c-84ba-a0f0aa9606aa"
      },
      "source": [
        "#in vgg16, image size must be 224*224\n",
        "image_size=[224,224]\n",
        "vgg=VGG16(input_shape=image_size+[3], weights='imagenet', include_top=False)\n",
        "vgg.output"
      ],
      "id": "e78347e0",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 7, 7, 512) dtype=float32 (created by layer 'block5_pool')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa16705e"
      },
      "source": [
        "#we will not going to train vgg layers\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable=False"
      ],
      "id": "aa16705e",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07548abe",
        "outputId": "62560491-7217-4285-ccf6-f0400bc11b7d"
      },
      "source": [
        "#to make the vgg16 recognise our dataclass from folders/directory\n",
        "folders=glob(r\"/content/drive/MyDrive/Dataset/dog_vs_cat/dataset/*\")\n",
        "print(len(folders))"
      ],
      "id": "07548abe",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "718caf19",
        "outputId": "7379c985-ecdc-48fd-d702-c253d509e56c"
      },
      "source": [
        "x=Flatten()(vgg.output)\n",
        "prediction=Dense(len(folders),activation='softmax')(x) #we can add more dense layer here to increase acuracy\n",
        "model=Model(inputs=vgg.input, outputs=prediction)\n",
        "model.summary()"
      ],
      "id": "718caf19",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 50178     \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9821d22"
      },
      "source": [
        "#model_train\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "id": "d9821d22",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f98da3b4",
        "outputId": "db17535a-f18c-4657-b847-6a0c24eb56db"
      },
      "source": [
        "epoch=3\n",
        "\n",
        "history= model.fit(train_generator,\n",
        "                  steps_per_epoch=len(train_generator),\n",
        "                  epochs=epoch,\n",
        "                  validation_data=validation_generator,\n",
        "                  validation_steps=len(validation_generator)\n",
        "                 )"
      ],
      "id": "f98da3b4",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "113/113 [==============================] - 669s 6s/step - loss: 0.1671 - accuracy: 0.9306 - val_loss: 0.2594 - val_accuracy: 0.8950\n",
            "Epoch 2/3\n",
            "113/113 [==============================] - 669s 6s/step - loss: 0.1328 - accuracy: 0.9522 - val_loss: 0.2121 - val_accuracy: 0.9100\n",
            "Epoch 3/3\n",
            "113/113 [==============================] - 672s 6s/step - loss: 0.1439 - accuracy: 0.9417 - val_loss: 0.3551 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "720cf3a3",
        "outputId": "98d2b615-924b-4467-86eb-7156dcc66a34"
      },
      "source": [
        " # Model Prediction\n",
        "\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_pred=image.load_img(r\"/content/drive/MyDrive/Dataset/dog_vs_cat/dataset/cats/cat.4027.jpg\",target_size=(224,224))\n",
        "\n",
        "img_pred=image.img_to_array(img_pred)\n",
        "img_pred=np.expand_dims(img_pred, axis=0)\n",
        "\n",
        "\n",
        "rslt = model.predict(img_pred)\n",
        "\n",
        "print(rslt)\n",
        "if rslt[0][0]>rslt[0][1]:\n",
        "    prediction=\"cat\"\n",
        "    \n",
        "    \n",
        "else:\n",
        "    prediction=\"dog\"\n",
        "print(prediction)\n"
      ],
      "id": "720cf3a3",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]]\n",
            "cat\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}